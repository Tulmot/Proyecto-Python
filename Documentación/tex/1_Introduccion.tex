\capitulo{1}{Introducción}

La minería de datos es un campo de 	las ciencias de la computación, que consisten en el análisis de grandes cantidades de datos para descubrir patrones.
Para ello se puede utilizar el aprendizaje automático, éste pertenece a un subcampo de las ciencias de computación y de la rama de inteligencia artificial, el objetivo del aprendizaje automático es desarrollar unas técnicas que permitan que las máquinas aprendan~\cite{wiki:datamining}.
Dentro de este aprendizaje se encuentra el aprendizaje supervisado, en él normalmente los conjuntos de datos suelen tener solo una variable a predecir, conocido como Single-Label, pero apareció el concepto de Multi-Label~\cite{multilabel2}, este hace referencia a los conjuntos de datos en lo que cada elemento de la base de datos puede pertenecer a más de una clase, como por ejemplo en el etiquetado de imágenes: en el que una imagen puede tener a la vez las etiquetas <<árbol>>, <<montaña>> y <<mar>>.

En este proyecto vamos a tratar de implementar diversos algoritmos de multi-clasificadores (\textit{ensembles}), para Multi-Label sobre la biblioteca de Python~\cite{python} Scikit-Learn~\cite{scikitlearn}. Se ha seguido la guía de estilo de Python (PeP~\cite{pep}) y las convecciones que se han observado en Sklearn (Scikit-Learn). Para que se entienda mejor y sea más gráfico, se han dibujado árboles y gráficas, mostrando los resultados al ejecutar dichos algoritmos sobre unos conjuntos de datos. Los algoritmos en los que nos vamos a centrar son Disturbing Neighbors~\cite{disturbingneighbors}, Random Oracles~\cite{randomoracles} y Rotation Forest~\cite{rotationforest}.

A lo largo del proyecto también veremos como funcionan los \textit{ensembles}.
Los métodos de \textit{ensembles} combinan las predicciones de unos clasificadores base, que están construidos mediante un algoritmo de aprendizaje para mejorar la solidez de si sólo tuviesemos un clasificador~\cite{ensemble}.
El éxito de un \textit{ensemble} requiere que un clasificadores base tengan exactitud y diversidad.
La ventaja de usar un \textit{ensemble} de clasificadores base consiste en la posibilidad que algunos de ellos pueden corregir una predicción incorrecta de otros, por lo que cuantos más clasificadores tengamos mas precisas serán las predicciones. 
¿Cómo puede un \textit{ensemble} de clasificadores base que han sido generados por el mismo algoritmo tener distintas salidas? Una de las estrategias que podemos usar para ello son los \textit{ensembles} homogéneos, es decir, mismo algoritmo entrenado con distinto conjunto de datos.
